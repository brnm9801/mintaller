{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d03de88-2e19-40e8-a211-1ace88429506",
   "metadata": {},
   "source": [
    "Minitaller OpenCV \n",
    "Brian Cordero Matamoros \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdccf0d-2663-4422-a62f-ec76a17c0657",
   "metadata": {},
   "source": [
    "\n",
    "Instalacion de python\n",
    "\n",
    "Salte este paso si ya lo tiene\n",
    "\n",
    "\n",
    "```bahs\n",
    "sudo apt update/\n",
    "sudo apt upgrade/\n",
    "sudo apt install python3\n",
    "##verifique que python esta instalado con \n",
    "python3 --version\n",
    "\n",
    "\n",
    "## si no tiene jupyter instalado\n",
    "\n",
    "pip install notebook\n",
    "```\n",
    "\n",
    "Creacion de un entorno Virtual \n",
    "\n",
    "Si nunca ha creado un entorni virtual utilice las sigueintes instruciones:\n",
    "\n",
    "-abra la consola o presione ctrl+alt+t)\n",
    "\n",
    "-ingrese el comando\n",
    "\n",
    "```bash\n",
    "python -m venv minitaller\n",
    "## si genera algun error\n",
    "apt install python3.10-venv\n",
    "\n",
    "## Ahora introduzca\n",
    "pwd\n",
    "## copie la direccion con ctrl+shift+c\n",
    "source <pwd>/minitaller/bin/activate\n",
    "\n",
    "\n",
    "```\n",
    "Clone el repositorio \n",
    "\n",
    "```bash\n",
    "git init/\n",
    "git clone https://github.com/brnm9801/mintaller.git\n",
    "```\n",
    "\n",
    "Ejecute el archivo requirements.txt\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "\n",
    "##Verifique que todo se instalo bien revisando el archivo\n",
    "cat requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ceae4e9-38ea-41f7-a624-5da3d5563367",
   "metadata": {},
   "source": [
    "Ahora se inicia con el mintaller de OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbddb9ed-7dfa-4bc5-a8f9-f046f7cec649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#!pip install matplotlib \n",
    "from IPython.display import display, Image\n",
    "from IPython.display import Video\n",
    "\n",
    "\n",
    "# Cargar la imagen\n",
    "image = cv2.imread(\"sample.jpeg\")\n",
    "\n",
    "# Mostrar la imagen\n",
    "cv2.imshow('Imagen de Paisaje', image)\n",
    "display(Image(filename='sample.jpeg'))\n",
    "## si muestar error use $ sudo apt install libgtk2.0-dev pkg-config\n",
    "\n",
    "## si muestar el error <cvShowImage> use https://chatgpt.com/share/66e92357-9c98-8003-ba62-6dad90257e8e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5dc9b5-dcd0-4fa1-a037-7168f8b05205",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Guardar la imagen en escala de grises\n",
    "cv2.imwrite('sample.jpeg', gray_image)\n",
    "display(Image(filename='sample.jpeg'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f970e608-dfb2-41db-91c0-cac13b4dd782",
   "metadata": {},
   "source": [
    "Ahora use algunos de los siguientes comandos y tome la captura de pantalla para su reporte \n",
    "\n",
    "-cv2.COLOR_GRAY2RGB\n",
    "-cv2.COLOR_GRAY2HSV\n",
    "-cv2.COLOR_GRAY2Lab\n",
    "-cv2.COLOR_GRAY2YUV\n",
    "-cv2.COLOR_GRAY2XYZ\n",
    "-cv2.COLOR_GRAY2HLS\n",
    "-cv2.COLOR_GRAY2LUV\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f9c92dd-651c-4e66-94db-a6135a8df62d",
   "metadata": {},
   "source": [
    "Ahora se usa la funcion canny para detectar bordes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72844182-cd67-4cf2-ab87-bed8657f47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray_image, threshold1=100, threshold2=200)\n",
    "cv2.imwrite('sample-edge.jpeg', edges)\n",
    "\n",
    "display(Image(filename='sample.jpeg'))\n",
    "display(Image(filename='sample-edge.jpeg'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47400741-84a2-43ec-94af-d362dcc0bce8",
   "metadata": {},
   "source": [
    "Pegue esta imagen en su reporte y explique si la imagen concuerda con los esperado al detectar los bordes\n",
    "\n",
    "\n",
    "Deteccion de Fondo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff64bac-4a51-4887-b94a-6327d483d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(gray_image, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "background = cv2.bitwise_and(image, image, mask=thresh)\n",
    "cv2.imwrite('sample-fondo.jpeg', background )\n",
    "display(Image(filename='sample.jpeg'))\n",
    "display(Image(filename='sample-fondo.jpeg'))\n",
    "cv2.imshow(\"sfwr\",background)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f74cdd8a-acb5-4fd4-8470-930fd3d11807",
   "metadata": {},
   "source": [
    "Pegue esta imagen en su reporte y comente si los bordes estan bien detectados y busque algun caso en el que no detecte de manera correcta el fondo\n",
    "\n",
    "Ahora vamos a hacer uso de la camara para poder ver el video de la webcam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf7a7d-19fc-4a40-aa6b-80423e43d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### si tiene disponible camara, no usar en jupyter\n",
    "##cap = cv2.VideoCapture(0)\n",
    "## si no se tiene camara\n",
    "cap = cv2.VideoCapture('istockphoto-1766316527-640_adpp_is.mp4')\n",
    "\n",
    "video_path = 'istockphoto-1766316527-640_adpp_is.mp4'\n",
    "\n",
    "# Muestra el video en el notebook\n",
    "Video(video_path, embed=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3443a793-7af1-4190-8d4a-8814f01f7211",
   "metadata": {},
   "source": [
    "Ahora se utilizara las siguientes lineas para hacer uso de un modelo preentrenado cargado en la libreria de opencv para deteccion de rostros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1b13f-c24d-44bd-a957-2ac9e472abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Carga \n",
    "## Si uso pip /usr/local/lib/python3.x/dist-packages/cv2/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "## si recompilo opencv /path/donde/recompilo/opencv/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "##cap = cv2.VideoCapture(0)\n",
    "face_classifier = cv2.CascadeClassifier('/home/brnm/Documents/minitaller/opencv/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    faces = face_classifier.detectMultiScale(blurred_image, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edfb5bf5-6f9a-4831-a4c8-662ceb637e5f",
   "metadata": {},
   "source": [
    "Tome una foto con la deteccion de rostros y subala en su reporte"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27638d42-ccf1-408d-85dc-354a35f388ac",
   "metadata": {},
   "source": [
    "Ahora corra el py llamado demostracion.py por medio del comando\n",
    "$ python3 demostracion.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
