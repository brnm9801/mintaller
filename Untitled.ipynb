{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d03de88-2e19-40e8-a211-1ace88429506",
   "metadata": {},
   "source": [
    "Minitaller OpenCV \n",
    "Brian Cordero Matamoros \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdccf0d-2663-4422-a62f-ec76a17c0657",
   "metadata": {},
   "source": [
    "\n",
    "Instalacion de python\n",
    "\n",
    "Salte este paso si ya lo tiene\n",
    "\n",
    "\n",
    "```bahs\n",
    "sudo apt update/\n",
    "sudo apt upgrade/\n",
    "sudo apt install python3\n",
    "##verifique que python esta instalado con \n",
    "python3 --version\n",
    "\n",
    "\n",
    "## si no tiene jupyter instalado\n",
    "\n",
    "pip install notebook\n",
    "```\n",
    "\n",
    "Creacion de un entorno Virtual \n",
    "\n",
    "Si nunca ha creado un entorni virtual utilice las sigueintes instruciones:\n",
    "\n",
    "-abra la consola o presione ctrl+alt+t)\n",
    "\n",
    "-ingrese el comando\n",
    "\n",
    "```bash\n",
    "python -m venv minitaller\n",
    "## si genera algun error\n",
    "apt install python3.10-venv\n",
    "\n",
    "## Ahora introduzca\n",
    "pwd\n",
    "## copie la direccion con ctrl+shift+c\n",
    "source <pwd>/minitaller/bin/activate\n",
    "\n",
    "\n",
    "```\n",
    "Clone el repositorio \n",
    "\n",
    "```bash\n",
    "git init/\n",
    "git clone https://github.com/brnm9801/mintaller.git\n",
    "```\n",
    "\n",
    "Ejecute el archivo requirements.txt\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "\n",
    "##Verifique que todo se instalo bien revisando el archivo\n",
    "cat requirements.txt\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ceae4e9-38ea-41f7-a624-5da3d5563367",
   "metadata": {},
   "source": [
    "Ahora se inicia con el mintaller de OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbddb9ed-7dfa-4bc5-a8f9-f046f7cec649",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Mostrar la imagen\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImagen de Paisaje\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## si muestar el error <cvShowImage> use https://chatgpt.com/share/66e92357-9c98-8003-ba62-6dad90257e8e\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la imagen\n",
    "image = cv2.imread('sample.jpeg')\n",
    "\n",
    "# Mostrar la imagen\n",
    "cv2.imshow('Imagen de Paisaje', image)\n",
    "\n",
    "## si muestar el error <cvShowImage> use https://chatgpt.com/share/66e92357-9c98-8003-ba62-6dad90257e8e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5dc9b5-dcd0-4fa1-a037-7168f8b05205",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m gray_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Guardar la imagen en escala de grises\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray_sample.jpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgray_image\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/highgui/src/window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Guardar la imagen en escala de grises\n",
    "cv2.imshow('gray_sample.jpeg', gray_image)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f970e608-dfb2-41db-91c0-cac13b4dd782",
   "metadata": {},
   "source": [
    "Ahora use algunos de los siguientes comandos y tome la captura de pantalla para su reporte \n",
    "\n",
    "-cv2.COLOR_GRAY2RGB\n",
    "-cv2.COLOR_GRAY2HSV\n",
    "-cv2.COLOR_GRAY2Lab\n",
    "-cv2.COLOR_GRAY2YUV\n",
    "-cv2.COLOR_GRAY2XYZ\n",
    "-cv2.COLOR_GRAY2HLS\n",
    "-cv2.COLOR_GRAY2LUV\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f9c92dd-651c-4e66-94db-a6135a8df62d",
   "metadata": {},
   "source": [
    "Ahora se usa la funcion canny para detectar bordes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72844182-cd67-4cf2-ab87-bed8657f47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray_image, threshold1=100, threshold2=200)\n",
    "cv2.imwrite('edges_sample.jpeg', edges)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Edges', edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47400741-84a2-43ec-94af-d362dcc0bce8",
   "metadata": {},
   "source": [
    "Pegue esta imagen en su reporte y explique si la imagen concuerda con los esperado al detectar los bordes\n",
    "\n",
    "\n",
    "Deteccion de Fondo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff64bac-4a51-4887-b94a-6327d483d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(gray_image, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "background = cv2.bitwise_and(image, image, mask=thresh)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Background', background)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f74cdd8a-acb5-4fd4-8470-930fd3d11807",
   "metadata": {},
   "source": [
    "Pegue esta imagen en su reporte y comente si los bordes estan bien detectados y busque algun caso en el que no detecte de manera correcta el fondo\n",
    "\n",
    "Ahora vamos a hacer uso de la camara para poder ver el video de la webcam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf7a7d-19fc-4a40-aa6b-80423e43d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## si no se tiene camara\n",
    "##cap = cv2.VideoCapture('path/to/your/video.mp4')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Apply Sepia tone\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2SEPIA)\n",
    "\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3443a793-7af1-4190-8d4a-8814f01f7211",
   "metadata": {},
   "source": [
    "Ahora se utilizara las siguientes lineas para hacer uso de un modelo preentrenado cargado en la libreria de opencv para deteccion de rostros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1b13f-c24d-44bd-a957-2ac9e472abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edfb5bf5-6f9a-4831-a4c8-662ceb637e5f",
   "metadata": {},
   "source": [
    "Tome una foto con la deteccion de rostros y subala en su reporte"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24037506-0f4a-4763-b8a8-7a155ada55c6",
   "metadata": {},
   "source": [
    "Ahora cree una imagen con ojo de pez de su camara\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a6789-253c-4c77-b10d-2f823a24f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisheye_effect(frame):\n",
    "    # Obtener las dimensiones de la imagen\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Crear el mapa de distorsión\n",
    "    K = np.array([[width, 0, width // 2],\n",
    "                  [0, width, height // 2],\n",
    "                  [0, 0, 1]])  # Matriz de cámara intrínseca\n",
    "\n",
    "    # Definir los parámetros de distorsión (simulando ojo de pez)\n",
    "    D = np.array([-0.3, 0.1, 0, 0])  # Distorsión radial\n",
    "\n",
    "    # Crear el mapa de transformación inversa para corregir la distorsión\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, (width, height), cv2.CV_16SC2)\n",
    "\n",
    "    # Aplicar la distorsión a la imagen\n",
    "    fisheye_img = cv2.remap(frame, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    \n",
    "    return fisheye_img\n",
    "\n",
    "def main():\n",
    "    # Iniciar la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: No se pudo abrir la cámara.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Leer el cuadro de la cámara\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error al capturar la imagen.\")\n",
    "            break\n",
    "\n",
    "        # Aplicar el efecto ojo de pez\n",
    "        fisheye_frame = fisheye_effect(frame)\n",
    "\n",
    "        # Mostrar el resultado\n",
    "        cv2.imshow('Efecto Ojo de Pez', fisheye_frame)\n",
    "\n",
    "        # Presiona 'q' para salir\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Liberar la cámara y cerrar las ventanas\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b999d096-74e5-479a-bb14-1b028f9c6192",
   "metadata": {},
   "source": [
    "Tome una captura y agreguela al documento."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6794cc8-0f3a-460f-b210-186be11faa56",
   "metadata": {},
   "source": [
    "Ahora por medio de consola ejecute el archivo demostracion.py y guarde los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac452a-c818-4fd0-9187-673b2d7f287c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
